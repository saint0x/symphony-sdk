<?xml version="1.0" encoding="UTF-8"?>
<symphony_sdk_reference version="0.4.4">
  
  <!-- COMPLETE Symphony SDK Technical Reference v0.4.4 - ALL FEATURES DOCUMENTED -->

  <installation>
    <npm>npm install symphonic@0.4.4</npm>
    <import>import { Symphony } from 'symphonic';</import>
  </installation>

  <configuration>
    <![CDATA[
const symphony = new Symphony({
  llm: {
    provider: 'openai',  // 'openai' | 'anthropic' | 'groq'
    model: 'gpt-4o-mini',
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0.7,
    maxTokens: 2048
  },
  db: {
    enabled: true,
    adapter: 'sqlite',  // 'sqlite' | 'postgres' | 'mysql'
    path: './symphony.db'
  },
  serviceRegistry: {
    enabled: true,
    maxRetries: 3,
    retryDelay: 1000
  },
  metrics: {
    enabled: true,
    detailed: true
  },
  logging: {
    level: LogLevel.INFO,
    format: 'json'
  }
});

await symphony.initialize();
    ]]>
  </configuration>

  <core_symphony_class>
    <properties>
      <property name="name">readonly string - 'Symphony'</property>
      <property name="state">ToolLifecycleState - PENDING | INITIALIZING | READY | ERROR</property>
      <property name="logger">Logger instance for Symphony logging</property>
      <property name="llm">LLMHandler instance for language model operations</property>
      <property name="metrics">IMetricsAPI for performance tracking</property>
      <property name="db">IDatabaseService for database operations</property>
      <property name="cache">CacheServiceWrapper with intelligence features</property>
      <property name="memory">MemoryServiceWrapper for short/long-term memory</property>
      <property name="streaming">StreamingServiceWrapper for real-time updates</property>
    </properties>

    <services>
      <service name="tool">IToolService - Tool creation and execution</service>
      <service name="agent">IAgentService - Agent creation and management</service>
      <service name="team">ITeamService - Multi-agent team coordination</service>
      <service name="pipeline">IPipelineService - Workflow pipeline execution</service>
      <service name="validation">IValidationManager - Configuration validation</service>
    </services>

    <methods>
      <method name="initialize()">Promise&lt;void&gt; - Initialize all services</method>
      <method name="getService(name)">Promise&lt;any&gt; - Get service by name</method>
      <method name="getState()">ToolLifecycleState - Current state</method>
      <method name="getConfig()">SymphonyConfig - Current configuration</method>
      <method name="updateConfig(config)">void - Update configuration</method>
      <method name="startMetric(id, metadata?)">void - Start performance metric</method>
      <method name="endMetric(id, metadata?)">void - End performance metric</method>
      <method name="getMetric(id)">any - Get metric data</method>
    </methods>
  </core_symphony_class>

  <tools_api>
    <service_interface>
      <method name="tool.create(config)">Promise&lt;Tool&gt; - Create custom tool</method>
      <method name="tool.execute(toolName, params)">Promise&lt;ToolResult&gt; - Execute tool</method>
      <method name="tool.getAvailable()">string[] - List available tools</method>
      <method name="tool.getInfo(toolName)">ToolConfig - Get tool configuration</method>
      <method name="tool.register(name, tool)">void - Register tool manually</method>
      <method name="tool.registry">ToolRegistry - Access tool registry</method>
      <method name="tool.initialize()">Promise&lt;void&gt; - Initialize tool service</method>
    </service_interface>

    <standard_tools>
      <tool name="webSearch">Search web for information</tool>
      <tool name="readFile">Read content from files</tool>
      <tool name="writeFile">Write content to files</tool>
      <tool name="parseDocument">Parse PDF, DOCX, etc.</tool>
      <tool name="writeCode">Generate code using LLM</tool>
      <tool name="createPlan">Create execution plans</tool>
      <tool name="ponder">Deep analysis and reasoning</tool>
    </standard_tools>

    <context_intelligence_tools>
      <tool name="validateCommandMapUpdate">Validate pattern updates for conflicts</tool>
      <tool name="updateLearningContext">Learn from execution results</tool>
      <tool name="executeContextPruning">Intelligent database cleanup</tool>
      <tool name="updatePatternStats">Track tool usage statistics</tool>
      <tool name="validateContextTreeUpdate">Ensure context consistency</tool>
    </context_intelligence_tools>

    <custom_tool_creation>
      <![CDATA[
// Create and register custom tool
const tool = await symphony.tool.create({
  name: 'dataProcessor',
  description: 'Process data with custom logic',
  type: 'data_processing',
  inputs: ['data', 'processingType'],
  outputs: ['processedData', 'metadata'],
  
  // NLP field for auto-learning patterns
  nlp: 'process data OR analyze * OR transform * OR handle data',
  
  handler: async (params) => {
    const { data, processingType } = params;
    const result = await customProcessing(data, processingType);
    return { success: true, result };
  },
  
  timeout: 30000,
  retry: { enabled: true, maxAttempts: 3, delay: 1000 },
  cache: { enabled: true, ttl: 3600 },
  validation: {
    schema: {
      data: { type: 'string', required: true },
      processingType: { type: 'string', enum: ['basic', 'advanced'] }
    }
  }
});

// Use the tool
const result = await tool.run({ data: 'input', processingType: 'advanced' });
      ]]>
    </custom_tool_creation>

    <tool_chaining>
      <![CDATA[
const chain: ToolChain = {
  id: 'research_workflow',
  name: 'Research and Analysis Workflow',
  steps: [
    {
      id: 'search',
      tool: 'webSearch',
      chained: '1',  // First step
      static_params: { query: 'AI developments 2024' }
    },
    {
      id: 'analyze',
      tool: 'ponder', 
      chained: '2',  // Second step
      input_mapping: { content: 'search.result' },
      depends_on: ['search']
    },
    {
      id: 'save',
      tool: 'writeFile',
      chained: '3',  // Final step
      input_mapping: { content: 'analyze.result' },
      static_params: { path: 'analysis.txt' },
      depends_on: ['analyze']
    }
  ],
  output_mapping: {
    searchResults: 'search.result',
    analysis: 'analyze.result',
    filePath: 'save.result'
  }
};

// Execute chain
const result = await symphony.chain.execute(chain, { startData: 'input' });
      ]]>
    </tool_chaining>

    <parallel_execution>
      <![CDATA[
// Parallel tool execution using decimal notation
const parallelChain: ToolChain = {
  id: 'parallel_analysis',
  steps: [
    { id: 'init', tool: 'ponder', chained: '1' },
    // These execute in parallel (same major number)
    { id: 'branch_a', tool: 'webSearch', chained: '2.1', depends_on: ['init'] },
    { id: 'branch_b', tool: 'parseDocument', chained: '2.2', depends_on: ['init'] },
    { id: 'branch_c', tool: 'dataProcessor', chained: '2.3', depends_on: ['init'] },
    // Merge results
    { id: 'merge', tool: 'writeFile', chained: '3', depends_on: ['branch_a', 'branch_b', 'branch_c'] }
  ]
};
      ]]>
    </parallel_execution>
  </tools_api>

  <agents_api>
    <service_interface>
      <method name="agent.create(config)">Promise&lt;Agent&gt; - Create agent</method>
      <method name="agent.initialize()">Promise&lt;void&gt; - Initialize agent service</method>
    </service_interface>

    <agent_object>
      <property name="name">string - Agent name</property>
      <property name="capabilities">string[] - Agent capabilities</property>
      <property name="tools">string[] - Available tools (includes context tools)</property>
      <property name="executor">AgentExecutor - Low-level executor</property>
      <method name="run(task)">Promise&lt;AgentResult&gt; - Execute task</method>
      <method name="selectTool(task)">Promise&lt;any&gt; - Intelligent tool selection</method>
    </agent_object>

    <agent_creation>
      <![CDATA[
const agent = await symphony.agent.create({
  name: 'ResearchAgent',
  description: 'Intelligent research assistant',
  task: 'Research topics and generate comprehensive reports',
  tools: ['webSearch', 'ponder', 'writeFile', 'parseDocument'],
  llm: {
    model: 'gpt-4o-mini',
    temperature: 0.3,
    maxTokens: 2048
  },
  
  // Option 1: Custom directives for personality
  directives: `You are a thorough researcher with expertise in:
    - Comprehensive web research and source verification
    - Critical analysis and synthesis of information
    - Clear, structured reporting with actionable insights
    Always cite sources and maintain objectivity.`,
  
  // Option 2: Complete systemPrompt override (ignores directives)
  // systemPrompt: 'Custom system prompt content...',
  // systemPrompt: './prompts/research-agent.xml',  // File-based
  
  maxCalls: 15,
  timeout: 120000,
  requireApproval: false,
  capabilities: ['research', 'analysis', 'documentation']
});
      ]]>
    </agent_creation>

    <system_prompt_override>
      <![CDATA[
// String-based system prompt (complete override)
const jsonAgent = await symphony.agent.create({
  name: 'JSONResponder',
  description: 'Structured JSON response agent',
  task: 'Provide responses in JSON format',
  tools: ['webSearch', 'ponder'],
  llm: 'gpt-4o-mini',
  
  systemPrompt: `You are a JSON Response Agent. ALWAYS respond in valid JSON:
{
  "response": "your main response",
  "confidence": "high|medium|low",
  "reasoning": "brief explanation",
  "tools_used": ["list of tools"],
  "action_taken": "what you did"
}
Never break from this JSON format.`,
  
  directives: 'Be friendly' // IGNORED when systemPrompt is set
});

// File-based system prompt
const codeAgent = await symphony.agent.create({
  name: 'CodeAnalyst',
  systemPrompt: './prompts/code-analyst.xml'  // Supports .xml, .txt, .md
});
      ]]>
    </system_prompt_override>

    <agent_execution>
      <![CDATA[
// Basic execution
const result = await agent.run('Research the latest AI developments');

// With callbacks and options
const result = await agent.run('Create comprehensive AI report', {
  onProgress: (update) => {
    console.log(`Status: ${update.status}`);
    console.log('Progress:', update.result);
  },
  onMetrics: (metrics) => console.log('Metrics:', metrics),
  timeout: 180000
});

// Tool chain execution
const chainResult = await agent.executor.executeToolChain(researchChain, {
  inputData: 'AI trends 2024',
  context: { userId: 'user123', sessionId: 'session456' }
});

// Tool selection
const toolSelection = await agent.selectTool('Analyze this dataset');
      ]]>
    </agent_execution>

    <automatic_context_intelligence>
      Every agent automatically receives context management tools and can:
      - Learn from execution patterns and update confidence scores
      - Validate new patterns for conflicts before adoption  
      - Prune old, ineffective context data for performance
      - Track tool usage statistics and success rates
      - Maintain context tree consistency and structure
    </automatic_context_intelligence>
  </agents_api>

  <teams_api>
    <service_interface>
      <method name="team.create(config)">Promise&lt;Team&gt; - Create team</method>
      <method name="team.initialize()">Promise&lt;void&gt; - Initialize team service</method>
    </service_interface>

    <team_object>
      <property name="name">string - Team name</property>
      <property name="coordinator">TeamCoordinator - Low-level coordinator</property>
      <method name="run(task, options?)">Promise&lt;TeamResult&gt; - Execute team task</method>
      <method name="getStatus()">any - Get team status</method>
      <method name="getContext()">any - Get team context</method>
    </team_object>

    <team_creation>
      <![CDATA[
const team = await symphony.team.create({
  name: 'AIResearchTeam',
  description: 'Collaborative AI research and development team',
  agents: [
    {
      name: 'Researcher',
      description: 'Web research specialist',
      task: 'Conduct thorough research on assigned topics',
      tools: ['webSearch', 'parseDocument'],
      llm: { model: 'gpt-4o-mini' },
      directives: 'Focus on authoritative sources and recent information.'
    },
    {
      name: 'Analyst',
      description: 'Data analysis specialist',
      task: 'Analyze research findings and identify patterns',
      tools: ['ponder', 'dataProcessor'],
      llm: { model: 'gpt-4o-mini' },
      directives: 'Provide deep analytical insights and trend identification.'
    },
    {
      name: 'Writer',
      description: 'Technical documentation specialist',
      task: 'Create clear, comprehensive reports',
      tools: ['writeFile', 'ponder'],
      llm: { model: 'gpt-4o-mini' },
      systemPrompt: `Structure all reports with:
1. Executive Summary
2. Detailed Findings
3. Key Insights
4. Recommendations
5. Next Steps`
    }
  ],
  capabilities: ['research', 'analysis', 'documentation'],
  manager: true,
  strategy: {
    name: 'Collaborative Research',
    description: 'Divide research tasks and synthesize results',
    coordinationRules: {
      maxParallelTasks: 3,
      taskTimeout: 300000
    }
  },
  delegationStrategy: {
    type: 'rule-based',
    rules: [
      { condition: 'high-priority', assignTo: ['Researcher', 'Analyst'] },
      { condition: 'analysis-required', assignTo: ['Analyst'] },
      { condition: 'documentation', assignTo: ['Writer'] }
    ]
  }
});
      ]]>
    </team_creation>

    <team_strategies>
      <strategy name="PARALLEL">All agents work simultaneously on different aspects</strategy>
      <strategy name="SEQUENTIAL">Agents work in sequence, passing results forward</strategy>
      <strategy name="PIPELINE">Structured workflow with defined handoffs</strategy>
      <strategy name="COLLABORATIVE">Dynamic collaboration based on task requirements</strategy>
      <strategy name="ROLE_BASED">Assignment based on agent capabilities</strategy>
    </team_strategies>

    <team_execution>
      <![CDATA[
// Basic team execution
const result = await team.run('Research and document latest AI frameworks');

// Advanced execution with strategy
const result = await team.run('Design comprehensive ML pipeline', {
  strategy: 'PIPELINE',
  priority: 1,
  timeout: 600000,
  requiredCapabilities: ['research', 'analysis'],
  onProgress: (update) => {
    console.log(`Team progress - Agent: ${update.agent}, Status: ${update.status}`);
  }
});

// Get team status and context
const status = team.getStatus();
const context = team.getContext();
      ]]>
    </team_execution>
  </teams_api>

  <pipelines_api>
    <service_interface>
      <method name="pipeline.create(config)">Promise&lt;Pipeline&gt; - Create pipeline</method>
      <method name="pipeline.initialize()">Promise&lt;void&gt; - Initialize pipeline service</method>
    </service_interface>

    <pipeline_object>
      <property name="name">string - Pipeline name</property>
      <property name="executor">PipelineExecutor - Low-level executor</property>
      <method name="run(input?)">Promise&lt;PipelineResult&gt; - Execute pipeline</method>
      <method name="getStatus()">any - Get pipeline status</method>
    </pipeline_object>

    <pipeline_creation>
      <![CDATA[
const pipeline = await symphony.pipeline.create({
  name: 'DataProcessingPipeline',
  description: 'End-to-end data processing workflow',
  version: '1.0.0',
  
  steps: [
    {
      id: 'ingestion',
      name: 'Data Ingestion',
      type: 'tool',
      tool: 'dataIngester',
      retryPolicy: { maxRetries: 3, backoffMs: 1000 }
    },
    {
      id: 'validation',
      name: 'Data Validation',
      type: 'tool',
      tool: 'dataValidator',
      dependencies: ['ingestion'],
      continueOnError: false
    },
    {
      id: 'processing',
      name: 'Parallel Processing',
      type: 'parallel',
      parallel: {
        steps: ['sentiment_analysis', 'trend_analysis'],
        waitForAll: true
      }
    },
    {
      id: 'sentiment_analysis',
      name: 'Sentiment Analysis',
      type: 'tool',
      tool: 'sentimentAnalyzer',
      dependencies: ['validation']
    },
    {
      id: 'trend_analysis',
      name: 'Trend Analysis',
      type: 'tool',
      tool: 'trendAnalyzer',
      dependencies: ['validation']
    },
    {
      id: 'output',
      name: 'Generate Output',
      type: 'tool',
      tool: 'outputGenerator',
      dependencies: ['processing']
    }
  ],
  
  variables: {
    outputFormat: 'json',
    qualityThreshold: 0.8
  },
  
  errorHandling: {
    strategy: 'retry',
    maxGlobalRetries: 3,
    fallbackPipeline: 'basic_processing'
  },
  
  concurrency: {
    maxParallelSteps: 5,
    resourceLimits: { memory: 1024, cpu: 80 }
  }
});
      ]]>
    </pipeline_creation>

    <conditional_pipelines>
      <![CDATA[
const conditionalPipeline = await symphony.pipeline.create({
  name: 'AdaptiveProcessing',
  steps: [
    {
      id: 'assessment',
      type: 'tool',
      tool: 'qualityAssessment'
    },
    {
      id: 'routing',
      type: 'condition',
      condition: {
        expression: 'assessment.quality > 0.8',
        ifTrue: 'advanced_processing',
        ifFalse: 'basic_processing'
      }
    },
    {
      id: 'advanced_processing',
      type: 'chain',
      chain: advancedChain,
      dependencies: ['routing']
    },
    {
      id: 'basic_processing',
      type: 'tool',
      tool: 'basicProcessor',
      dependencies: ['routing']
    }
  ]
});
      ]]>
    </conditional_pipelines>

    <pipeline_execution>
      <![CDATA[
// Basic pipeline execution
const result = await pipeline.run({
  inputData: 'raw data',
  parameters: { depth: 'comprehensive' }
});

// With monitoring and callbacks
const result = await pipeline.run(inputData, {
  onStepComplete: (step, result) => {
    console.log(`Step ${step.id}: ${result.success}`);
    if (result.failureAnalysis) {
      console.log('Failure analysis:', result.failureAnalysis);
    }
  },
  onMetrics: (metrics) => console.log('Metrics:', metrics),
  timeout: 300000
});

// Get pipeline status
const status = pipeline.getStatus();
const optimizations = pipeline.executor.getOptimizationRecommendations();
const circuitBreakers = pipeline.executor.getCircuitBreakerStatus('step_id');
      ]]>
    </pipeline_execution>
  </pipelines_api>

  <database_api>
    <service_interface>
      <method name="db.initialize(config?)">Promise&lt;void&gt; - Initialize database</method>
      <method name="db.table(name)">Table operations</method>
      <method name="db.query(sql, params?)">Promise&lt;any[]&gt; - Raw SQL query</method>
      <method name="db.execute(sql, params?)">Promise&lt;void&gt; - Execute SQL</method>
      <method name="db.transaction(callback)">Promise&lt;any&gt; - Database transaction</method>
      <method name="db.healthCheck()">Promise&lt;any&gt; - Health check</method>
      <method name="db.recordToolExecution(data)">Promise&lt;void&gt; - Record tool execution</method>
    </service_interface>

    <table_operations>
      <![CDATA[
// Table operations
const table = symphony.db.table('users');

// Insert
await table.insert({ name: 'John', email: 'john@example.com' });

// Find
const users = await table.find({ active: true });
const user = await table.findOne({ id: 123 });

// Update
await table.update({ id: 123 }, { name: 'Jane' });

// Delete
await table.delete({ id: 123 });

// Count
const count = await table.count({ active: true });
      ]]>
    </table_operations>

    <database_transactions>
      <![CDATA[
// Database transactions
const result = await symphony.db.transaction(async (tx) => {
  await tx.table('users').insert({ name: 'John' });
  await tx.table('profiles').insert({ userId: 1, bio: 'Developer' });
  return { success: true };
});
      ]]>
    </database_transactions>
  </database_api>

  <cache_api>
    <service_interface>
      <method name="cache.get(key, namespace?)">Promise&lt;any&gt; - Get cached value</method>
      <method name="cache.set(key, value, ttl?, namespace?)">Promise&lt;void&gt; - Set cached value</method>
      <method name="cache.delete(key, namespace?)">Promise&lt;void&gt; - Delete cached value</method>
      <method name="cache.has(key, namespace?)">Promise&lt;boolean&gt; - Check if key exists</method>
      <method name="cache.clear(namespace?)">Promise&lt;void&gt; - Clear cache</method>
      <method name="cache.getIntelligence(userInput, options?)">Promise&lt;IntelligenceResult&gt; - Get cache intelligence</method>
      <method name="cache.recordToolExecution(data)">Promise&lt;void&gt; - Record tool execution</method>
      <method name="cache.getPatternAnalytics()">Promise&lt;any&gt; - Get pattern analytics</method>
      <method name="cache.getContextAnalytics()">Promise&lt;any&gt; - Get context analytics</method>
      <method name="cache.getGlobalStats()">any - Get global statistics</method>
      <method name="cache.clearCaches()">void - Clear all caches</method>
      <method name="cache.healthCheck()">Promise&lt;any&gt; - Health check</method>
    </service_interface>

    <cache_operations>
      <![CDATA[
// Basic cache operations
await symphony.cache.set('user:123', userData, 3600); // TTL in seconds
const user = await symphony.cache.get('user:123');
const exists = await symphony.cache.has('user:123');
await symphony.cache.delete('user:123');

// Namespaced cache
await symphony.cache.set('config', data, 7200, 'app');
const config = await symphony.cache.get('config', 'app');
await symphony.cache.clear('app'); // Clear namespace

// Cache intelligence
const intelligence = await symphony.cache.getIntelligence('search for AI trends', {
  enablePatternMatching: true,
  enableContextTrees: true,
  fastPathThreshold: 0.85
});

// Analytics
const patternAnalytics = await symphony.cache.getPatternAnalytics();
const contextAnalytics = await symphony.cache.getContextAnalytics();
const globalStats = symphony.cache.getGlobalStats();
      ]]>
    </cache_operations>
  </cache_api>

  <memory_api>
    <service_interface>
      <method name="memory.store(key, value, type?, options?)">Promise&lt;void&gt; - Store memory</method>
      <method name="memory.retrieve(key, type?, options?)">Promise&lt;any&gt; - Retrieve memory</method>
      <method name="memory.search(query)">Promise&lt;MemoryEntry[]&gt; - Search memories</method>
      <method name="memory.delete(key, type?, namespace?)">Promise&lt;boolean&gt; - Delete memory</method>
      <method name="memory.clear(type?, namespace?)">Promise&lt;number&gt; - Clear memories</method>
      <method name="memory.aggregate(query)">Promise&lt;AggregationResult&gt; - Aggregate memories</method>
      <method name="memory.getStats()">Promise&lt;MemoryStats&gt; - Get memory statistics</method>
      <method name="memory.healthCheck()">Promise&lt;any&gt; - Health check</method>
      <method name="memory.createMemoryInstance(sessionId?, namespace?)">Memory - Create legacy memory</method>
    </service_interface>

    <memory_operations>
      <![CDATA[
// Store memories
await symphony.memory.store('conversation:123', conversationData, 'short_term', {
  sessionId: 'session_456',
  namespace: 'chat',
  metadata: { timestamp: Date.now(), userId: 'user_789' },
  tags: ['conversation', 'ai', 'help'],
  customTTL: 7200
});

// Retrieve memories
const conversation = await symphony.memory.retrieve('conversation:123', 'short_term', {
  namespace: 'chat',
  includeMetadata: true
});

// Search memories
const memories = await symphony.memory.search({
  namespace: 'chat',
  tags: ['conversation'],
  timeRange: { start: new Date('2024-01-01'), end: new Date() },
  limit: 50,
  orderBy: 'timestamp',
  orderDirection: 'desc'
});

// Long-term memory
await symphony.memory.store('user_preferences', preferences, 'long_term');
const prefs = await symphony.memory.retrieve('user_preferences', 'long_term');

// Aggregation and analytics
const aggregation = await symphony.memory.aggregate({
  namespace: 'chat',
  aggregationType: 'summary',
  groupBy: 'tags',
  timeRange: { start: new Date('2024-01-01'), end: new Date() }
});

// Memory statistics
const stats = await symphony.memory.getStats();
console.log(`Total memories: ${stats.totalEntries}`);
console.log(`Short-term: ${stats.shortTerm.count}, Long-term: ${stats.longTerm.count}`);
      ]]>
    </memory_operations>
  </memory_api>

  <streaming_api>
    <service_interface>
      <method name="streaming.createStream(options)">string - Create stream and return ID</method>
      <method name="streaming.updateProgress(streamId, progress)">void - Update stream progress</method>
      <method name="streaming.completeStream(streamId, finalData?)">void - Complete stream</method>
      <method name="streaming.errorStream(streamId, error)">void - Error stream</method>
      <method name="streaming.subscribe(streamId, callback)">Function - Subscribe to stream updates</method>
      <method name="streaming.getActiveStreams()">string[] - Get active stream IDs</method>
      <method name="streaming.getStreamStatus(streamId)">any - Get stream status</method>
      <method name="streaming.getStats()">StreamingStats - Get streaming statistics</method>
      <method name="streaming.healthCheck()">Promise&lt;any&gt; - Health check</method>
    </service_interface>

    <streaming_operations>
      <![CDATA[
// Create stream for real-time updates
const streamId = symphony.streaming.createStream({
  type: 'agent',  // 'agent' | 'team' | 'pipeline' | 'tool' | 'chain'
  context: {
    id: 'operation-123',
    name: 'DataAnalysis',
    description: 'Real-time data analysis operation'
  },
  options: {
    bufferSize: 100,
    updateInterval: 1000
  }
});

// Subscribe to stream updates
const unsubscribe = symphony.streaming.subscribe(streamId, (update) => {
  console.log('Stream update:', {
    type: update.type,           // 'progress' | 'complete' | 'error'
    progress: update.progress,   // 0-100
    status: update.status,       // Status message
    data: update.data,          // Any additional data
    timestamp: update.timestamp
  });
  
  if (update.type === 'complete') {
    console.log('Operation completed!', update.data);
    unsubscribe();
  }
  
  if (update.type === 'error') {
    console.error('Operation failed:', update.error);
    unsubscribe();
  }
});

// Update progress during operation
symphony.streaming.updateProgress(streamId, {
  progress: 50,
  status: 'Processing data chunk 5/10',
  data: { processed: 500, total: 1000, currentChunk: 5 }
});

// Complete the stream
symphony.streaming.completeStream(streamId, {
  finalResult: 'Analysis complete',
  summary: 'Processed 1000 records successfully',
  totalTime: 45000
});

// Get streaming statistics
const stats = symphony.streaming.getStats();
console.log(`Active streams: ${stats.activeStreams}`);
console.log(`Total streams created: ${stats.totalStreamsCreated}`);
      ]]>
    </streaming_operations>
  </streaming_api>

  <llm_api>
    <service_interface>
      <property name="llm">LLMHandler - Language model handler</property>
      <method name="llm.setCacheService(cache)">void - Set cache service</method>
      <method name="llm.generateResponse(prompt, options?)">Promise&lt;string&gt; - Generate LLM response</method>
      <method name="llm.getProvider()">string - Get current provider</method>
      <method name="llm.getModel()">string - Get current model</method>
    </service_interface>

    <llm_operations>
      <![CDATA[
// Direct LLM usage
const response = await symphony.llm.generateResponse('Explain quantum computing', {
  temperature: 0.7,
  maxTokens: 1000,
  model: 'gpt-4o-mini'
});

// Get LLM info
const provider = symphony.llm.getProvider(); // 'openai'
const model = symphony.llm.getModel(); // 'gpt-4o-mini'
      ]]>
    </llm_operations>
  </llm_api>

  <metrics_api>
    <service_interface>
      <method name="metrics.start(id, metadata?)">void - Start metric</method>
      <method name="metrics.end(id, metadata?)">void - End metric</method>
      <method name="metrics.get(id)">any - Get metric</method>
      <method name="metrics.update(id, metadata)">void - Update metric</method>
      <method name="metrics.getAll()">Record&lt;string, any&gt; - Get all metrics</method>
    </service_interface>

    <metrics_operations>
      <![CDATA[
// Start timing an operation
symphony.metrics.start('data_processing', { 
  operation: 'batch_process',
  batchSize: 1000 
});

// Update metric with additional data
symphony.metrics.update('data_processing', { 
  currentProgress: 50,
  estimatedTimeRemaining: 30000 
});

// End the metric
symphony.metrics.end('data_processing', { 
  recordsProcessed: 1000,
  status: 'success' 
});

// Get specific metric
const metric = symphony.metrics.get('data_processing');
console.log(`Processing took: ${metric.endTime - metric.startTime}ms`);

// Get all metrics
const allMetrics = symphony.metrics.getAll();
      ]]>
    </metrics_operations>
  </metrics_api>

  <validation_api>
    <service_interface>
      <method name="validation.validate(config, type)">Promise&lt;ValidationResult&gt; - Validate configuration</method>
      <method name="validation.initialize()">Promise&lt;void&gt; - Initialize validation service</method>
    </service_interface>

    <validation_operations>
      <![CDATA[
// Validate configuration
const result = await symphony.validation.validate(agentConfig, 'agent');
if (!result.isValid) {
  console.error('Validation errors:', result.errors);
}

// Validation result structure
interface ValidationResult {
  isValid: boolean;
  errors: string[];
}
      ]]>
    </validation_operations>
  </validation_api>

  <context_intelligence_api>
    <overview>NEW in v0.4.4: Context Intelligence API provides emergent agent capabilities</overview>
    
    <direct_usage>
      <![CDATA[
// Execute context intelligence operations directly
const pruning = await symphony.tool.execute('executeContextPruning', {
  maxAge: 24 * 60 * 60 * 1000, // 24 hours
  minConfidence: 0.3,
  keepRecentCount: 50
});

const learning = await symphony.tool.execute('updateLearningContext', {
  toolName: 'webSearch',
  parameters: { query: 'AI trends' },
  result: { success: true },
  success: true,
  userFeedback: 'positive'
});

const validation = await symphony.tool.execute('validateCommandMapUpdate', {
  nlpPattern: 'create config files OR setup configuration',
  toolName: 'configManager',
  operation: 'add',
  confidence: 0.8
});

const stats = await symphony.tool.execute('updatePatternStats', {
  nlpPattern: 'analyze data OR process information',
  toolName: 'dataAnalyzer',
  success: true,
  executionTime: 2500
});

const treeValidation = await symphony.tool.execute('validateContextTreeUpdate', {
  sessionId: 'session_123',
  maxNodes: 50,
  operation: 'build'
});
      ]]>
    </direct_usage>
  </context_intelligence_api>

  <best_practices>
    <context_intelligence>
      - Include meaningful 'nlp' fields in custom tools for automatic pattern learning
      - Let agents use context management tools naturally for self-optimization
      - Use specific, non-conflicting NLP patterns to avoid tool selection ambiguity
      - Trust intelligent pruning system to preserve valuable data while removing bloat
      - Monitor pattern confidence scores to identify successful vs. struggling tools
    </context_intelligence>
    
    <tool_development>
      - Implement proper error handling and validation in custom tools
      - Use caching for expensive operations with appropriate TTL
      - Set reasonable timeouts based on expected execution time
      - Include retry logic for transient failures with exponential backoff
      - Provide clear descriptions and comprehensive parameter documentation
      - Use the 'nlp' field for natural language pattern learning
    </tool_development>
    
    <agent_design>
      - Use directives for personality/behavior, systemPrompt for complete control
      - Set reasonable maxCalls limits (5-15) to prevent runaway execution
      - Choose appropriate tools for agent capabilities and task requirements
      - Test agents with various input types and edge cases
      - Enable detailed logging during development for debugging insights
      - Trust agents to use context intelligence features when beneficial
    </agent_design>
    
    <team_coordination>
      - Define clear capabilities for each team member
      - Use appropriate execution strategies for different task types
      - Implement proper delegation logic for complex workflows
      - Monitor team performance and adjust strategies accordingly
      - Ensure agents have complementary skill sets
      - Set reasonable coordination rules and timeout values
    </team_coordination>
    
    <pipeline_optimization>
      - Design steps with clear dependencies and proper error handling
      - Use parallel execution where steps are independent
      - Implement conditional logic for adaptive processing
      - Set appropriate resource limits and concurrency controls
      - Monitor pipeline metrics and optimize bottlenecks
      - Use fallback pipelines for error scenarios
    </pipeline_optimization>
    
    <database_usage>
      - Use transactions for multi-table operations
      - Implement proper indexing for frequently queried fields
      - Monitor database performance and optimize slow queries
      - Use connection pooling for high-traffic applications
      - Implement proper backup and recovery strategies
      - Consider database sharding for large-scale deployments
    </database_usage>
    
    <memory_cache>
      - Use appropriate memory types (short_term vs long_term) based on data lifecycle
      - Implement proper namespacing for multi-tenant applications
      - Use tags and metadata for flexible memory retrieval
      - Monitor memory usage and implement cleanup strategies
      - Use aggregation features for analytics and insights
      - Consider memory compression for large datasets
    </memory_cache>
    
    <streaming_optimization>
      - Use appropriate buffer sizes based on data volume
      - Implement proper error handling for stream failures
      - Monitor stream performance and adjust update intervals
      - Use stream compression for large payloads
      - Implement proper cleanup for completed streams
      - Consider stream persistence for critical operations
    </streaming_optimization>
    
    <performance>
      - Use tool chaining for related operations to reduce overhead
      - Leverage parallel execution where possible (2.1, 2.2, 2.3 pattern)
      - Enable intelligent caching for frequently used operations
      - Let Context Intelligence maintain optimal database performance
      - Monitor metrics and optimize based on performance profiles
      - Use streaming for real-time visibility into long-running operations
    </performance>
    
    <error_handling>
      - Always check result.success before accessing result.result
      - Use try-catch blocks around all Symphony operations
      - Implement circuit breaker patterns for external dependencies
      - Set appropriate timeouts for long-running operations
      - Use proper logging for debugging and monitoring
      - Implement graceful degradation for service failures
    </error_handling>
  </best_practices>

  <troubleshooting>
    <context_intelligence>
      <issue name="Context Intelligence not working">
        <solution>Ensure v0.4.4+, verify database enabled and accessible, check agent logs for context tool availability</solution>
      </issue>
      <issue name="NLP patterns not learning">
        <solution>Verify tools registered with 'nlp' field, check database contains execution records, ensure agents executing tools</solution>
      </issue>
      <issue name="Pattern conflicts">
        <solution>Use validateCommandMapUpdate to check conflicts, make patterns more specific, review confidence scores</solution>
      </issue>
    </context_intelligence>
    
    <tools>
      <issue name="Tools not found">
        <solution>Check tool names match exactly, verify tools are registered, ensure standard tools initialized</solution>
      </issue>
      <issue name="Tool execution fails">
        <solution>Check parameter validation, verify tool handler implementation, review timeout settings</solution>
      </issue>
      <issue name="Chain execution fails">
        <solution>Check dependency order, input mappings, chained field decimal notation, ensure all tools available</solution>
      </issue>
    </tools>
    
    <agents>
      <issue name="SystemPrompt not working">
        <solution>Ensure v0.4.4+, check file paths for file-based prompts, remember systemPrompt overrides directives</solution>
      </issue>
      <issue name="Agent gives generic responses">
        <solution>Check LLM configuration, directives format, tool descriptions, consider systemPrompt for stronger control</solution>
      </issue>
      <issue name="Agent tool selection poor">
        <solution>Review agent capabilities, check tool descriptions, verify context intelligence is learning patterns</solution>
      </issue>
    </agents>
    
    <teams>
      <issue name="Team coordination problems">
        <solution>Review delegation strategy, agent capabilities, execution strategy, check coordination rules and timeouts</solution>
      </issue>
      <issue name="Agents not collaborating">
        <solution>Verify team strategy settings, check agent compatibility, review task assignment logic</solution>
      </issue>
    </teams>
    
    <pipelines>
      <issue name="Pipeline performance issues">
        <solution>Check resource limits, enable parallel execution, optimize step dependencies, monitor pipeline metrics</solution>
      </issue>
      <issue name="Pipeline steps failing">
        <solution>Review step dependencies, check error handling configuration, verify tool availability</solution>
      </issue>
    </pipelines>
    
    <database>
      <issue name="Database connection issues">
        <solution>Check database configuration, verify connection string, ensure database server is running</solution>
      </issue>
      <issue name="Query performance issues">
        <solution>Review query structure, add appropriate indexes, consider connection pooling</solution>
      </issue>
    </database>
    
    <memory_cache>
      <issue name="Memory/Cache issues">
        <solution>Verify database persistence, check connection settings, run intelligent cleanup, monitor cache hit rates</solution>
      </issue>
      <issue name="Memory retrieval slow">
        <solution>Review query complexity, add appropriate indexes, consider memory optimization strategies</solution>
      </issue>
    </memory_cache>
    
    <streaming>
      <issue name="Streaming updates not received">
        <solution>Check stream subscription, verify update interval settings, ensure proper stream lifecycle management</solution>
      </issue>
      <issue name="Stream performance issues">
        <solution>Adjust buffer sizes, review update frequency, monitor stream statistics</solution>
      </issue>
    </streaming>
  </troubleshooting>

  <version_info>
    <current_version>0.4.4</current_version>
    <key_features>
      <feature>Context Intelligence API with emergent agent capabilities</feature>
      <feature>Auto-learning patterns via NLP field in custom tools</feature>
      <feature>Intelligent database pruning (89% bloat reduction)</feature>
      <feature>System prompt override for complete agent control</feature>
      <feature>Advanced tool chaining with parallel execution</feature>
      <feature>Multi-agent team collaboration with intelligent delegation</feature>
      <feature>Conditional pipelines with adaptive routing</feature>
      <feature>Real-time streaming for operation monitoring</feature>
      <feature>Comprehensive memory management (short/long-term)</feature>
      <feature>Advanced caching with intelligence features</feature>
      <feature>Full database operations with multiple adapters</feature>
      <feature>Comprehensive metrics and performance tracking</feature>
      <feature>Configuration validation and error handling</feature>
    </key_features>
    <compatibility>
      <node>>=18.0.0</node>
      <typescript>^5.7.2</typescript>
      <databases>SQLite 3.x, PostgreSQL 12+, MySQL 8+</databases>
      <llm_providers>OpenAI, Anthropic, Groq</llm_providers>
    </compatibility>
  </version_info>

</symphony_sdk_reference>